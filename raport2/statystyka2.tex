\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[export]{adjustbox}
\usepackage{mathtools,amsthm,amssymb,icomma,upgreek,xfrac,enumerate, bbm,titlesec,lmodern,polski,derivative,geometry,multicol,titling,graphicx,url,amsmath,caption,lipsum,float,longtable,booktabs}
\usepackage[table,xcdraw]{xcolor}
\usepackage[hidelinks,breaklinks,pdfusetitle,pdfdisplaydoctitle]{hyperref}
\setlength{\droptitle}{-1cm}
\mathtoolsset{showonlyrefs,mathic}
\title{Statystyka Stosowana raport 2}
\author{Adam Wrzesiński, Joanna Kołaczek}
\date{18.07.2022}
\newtheoremstyle{break}
{\topsep}{\topsep}%
{\normalfont}{}%
{\bfseries}{}%
{\newline}{}%
\theoremstyle{break}
\newtheorem{zadanie}{Zadanie} 
\newtheorem*{rozwiazanie}{Rozwiązanie}

\titleformat*{\section}{\LARGE\bfseries}
\titleformat*{\subsection}{\Large\bfseries}
\titleformat*{\subsubsection}{\large\bfseries}
\titleformat*{\paragraph}{\large\bfseries}
\titleformat*{\subparagraph}{\large\bfseries}

%% KOMENDY:
\newcommand*{\e}{\mathrm{e}}
\newcommand{\hyline}[2]{%
	$#1$\> --\kern.5em #2 \\}


%% OPERATORY:
% `\diff` od „differential”, czyli odpowiednika słowa „różniczka” w języku
% angielskim.
\DeclareMathOperator{\diff}{d\!}
\newcommand{\indep}{\perp \!\!\! \perp}
\DeclareMathOperator{\EX}{\mathbb{E}}
\newcommand*{\E}{\mathrm{e}}



\begin{document}
	\maketitle
	\tableofcontents
	\clearpage
\section*{Wstęp}
	
	Niniejszy raport powstał na potrzeby realizacji laboratorium ze Statystyki Stosowanej, prowadzonych przez dr inż. Aleksandrę Grzesiek, do wykładu dr hab. inż. Krzysztofa Burneckiego. Będziemy testować hipotezy statystyczne dla wartości średniej i wariancji w rodzinie rozkładów normalnych. Zobrazujemy także obszary krytyczne, wyznaczymy p-wartości oraz prawdopodobieństwo wystąpienia błędów I i II rodzaju. Życzymy miłej lektury.
	
\section*{Zadanie 1}
Dysponujemy próbą danych z rozkładu $N(\mu,0.2)$ [\ref{fig:hist}].
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{hist1.png}
		\caption{Histogram}
		\label{fig:hist}
	\end{center}
\end{figure}
Nasza hipoteza zerowa to $H_0: \mu_0 = 1.5$. Statystykę testową wyznaczamy ze wzoru :
$$Z = \frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}}.$$
Jeśli $H_0$ jest prawdziwa to $Z\sim N(0,1)$. Aby obliczyć średnią $\bar{X}$ użyjemy wzoru:
$$\bar{X}=\frac{1}{n}\sum\limits_{i=1}^{n}x_i$$
W naszym przypadku $\bar{X}=1.455$, $z=-7.041$.
Na poziomie istotności $\alpha = 0.05$ weryfikujemy kolejne hipotezy alternatywne $H_1$:

\subsection*{$\mu \ne 1.5$}
	\begin{itemize}
		\item Obszar krytyczny $c=\{x: x\leq -z_{1-\alpha/2} \lor x\geq z_{1-\alpha/2}\}$.
		\item p-wartość $p=2P_{H_0}(Z\geq|z|)$
	\end{itemize}
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{Z1.1.png}
		\caption{}
		\label{fig:1}
	\end{center}
\end{figure}
	W naszym przypadku $c=(-\infty,-1.96)\cup (1.96,\infty)$ oraz $p=1.9\cdot 10^{-12}$.\\
	Zaznaczamy na wykresie [\ref{fig:1}]  $c$ oraz statystykę $z$. Ponieważ statystyka $z$ znalazła się w obszarze krytycznym możemy przyjąć naszą hipotezę alternatywną $H_1: \mu \ne 1.5$. Ponadto p-wartość jest bardzo mała - prawie zawsze odrzucimy hipotezę zerową.

\subsection*{$\mu > 1.5$}	
	\begin{itemize}
		\item Obszar krytyczny $c=\{x: x\geq z_{1-\alpha}\}$.
		\item p-wartość $p=P_{H_0}(Z\geq z)$
	\end{itemize}
	\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{Z1.2.png}
		\caption{}
		\label{fig:2}
	\end{center}
	\end{figure}
	W naszym przypadku $c=(1.64,\infty)$ oraz $p=0.999$.\\
	Zaznaczamy na wykresie [\ref{fig:2}]  $c$ oraz statystykę $z$. Ponieważ statystyka $z$ znalazła się poza obszarem krytycznym odrzucamy hipotezę alternatywną, duża p-wartość również wskazuje na to, że nie możemy odrzucić hipotezy zerowej.

\subsection*{$\mu < 1.5$}
\begin{itemize}
	\item Obszar krytyczny $c=\{x: x\leq -z_{1-\alpha}\}$.
	\item p-wartość $p=P_{H_0}(Z\leq z)$
\end{itemize}
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{Z1.3.png}
		\caption{}
		\label{fig:3}
	\end{center}
\end{figure}
W naszym przypadku $c=(-\infty,-1.64)$ oraz $p=9.51\cdot 10^{-13}$.\\
Zaznaczamy na wykresie [\ref{fig:3}]  $c$ oraz statystykę $z$. Ponieważ statystyka $z$ znalazła się w obszarze krytycznym możemy przyjąć naszą hipotezę alternatywną $H_1: \mu < 1.5$. Ponadto p-wartość jest bardzo mała - prawie zawsze odrzucimy hipotezę zerową.\\ \\
\section*{Zadanie 2}
Dysponujemy próbą danych z rozkładu $N(0.2,\sigma^2)$ [\ref{fig:hist2}].
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{hist2.png}
		\caption{Histogram}
		\label{fig:hist2}
	\end{center}
\end{figure}
Nasza hipoteza zerowa to $H_0: \sigma^2_0 = 1.5$. Statystykę testową obliczamy ze wzoru:
$$Z=\frac{(n-1)S^2}{\sigma^2_0},$$ 
gdzie wariancja:
$$S^2=\frac{1}{n-1}\sum\limits_{i=1}^{n}(x_i - \overline{x})^2$$
W naszym przypadku $S^2=1.668$, $z=1110.968$.
Na poziomie istotności $\alpha = 0.05$ weryfikujemy kolejne hipotezy alternatywne $H_1$:

\subsection*{$\sigma^2 \ne 1.5$}
\begin{itemize}
	\item Obszar krytyczny $c=\{x: x^2\leq \chi^2_{\alpha/2,n-1} \lor x^2\geq \chi^2_{1-\alpha/2,n-1}\}$.
	\item p-wartość $p=2min(P_{H_0}(Z\leq z),P_{H_0}(Z\geq z))$
\end{itemize}
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{Z2.1.png}
		\caption{}
		\label{fig:4}
	\end{center}
\end{figure}
W naszym przypadku $c=[0,~913.3)\cup (1088.487,~\infty)$ oraz $p=0.015$.\\
Zaznaczamy na wykresie [\ref{fig:4}]  $c$ oraz statystykę $z$. Ponieważ statystyka $z$ znalazła się w obszarze krytycznym możemy przyjąć naszą hipotezę alternatywną $H_1: \mu \ne 1.5$. Ponadto p-wartość jest bardzo mała - prawie zawsze odrzucimy hipotezę zerową.

\subsection*{$\sigma^2  > 1.5$}	
\begin{itemize}
	\item Obszar krytyczny $c=\{x: x^2\geq \chi^2_{1-\alpha,n-1}\}$.
	\item p-wartość $p=P_{H_0}(Z\geq z)$
\end{itemize}
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{Z2.2.png}
		\caption{}
		\label{fig:5}
	\end{center}
\end{figure}
W naszym przypadku $c=[1073.643,\infty)$ oraz $0.008$.\\
Zaznaczamy na wykresie [\ref{fig:5}]  $c$ oraz statystykę $z$. Ponieważ statystyka $z$ znalazła się w obszarze krytycznym możemy przyjąć naszą hipotezę alternatywną $H_1: \mu \ne 1.5$. Ponadto p-wartość jest bardzo mała - prawie zawsze odrzucimy hipotezę zerową.

\subsection*{$\sigma^2  < 1.5$}
\begin{itemize}
	\item Obszar krytyczny $c=\{x: x^2\leq \chi^2_{\alpha,n-1}\}$.
	\item p-wartość $p=P_{H_0}(Z\leq z)$
\end{itemize}
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{Z2.3.png}
		\caption{}
		\label{fig:6}
	\end{center}
\end{figure}
W naszym przypadku $c=[0,~926.631)$ oraz $p=0.992$.\\
Zaznaczamy na wykresie [\ref{fig:6}]  $c$ oraz statystykę $z$. Ponieważ statystyka $z$ znalazła się poza obszarem krytycznym odrzucamy hipotezę alternatywną, duża p-wartość również wskazuje na to, że nie możemy odrzucić hipotezy zerowej.\\ 

\paragraph{Co stanie się kiedy zwiększymy bądź zmniejszymy poziom istotności?} 
W~przypadku zwiększenia poziomu istotności $\alpha$, zwiększy się nasz obszar krytyczny - test stanie się mniej wiarygodny. Zmniejszając poziom istotności, zmniejszamy obszar krytyczny - test jest bardziej wiarygodny. Można zatem powiedzieć, że najbardziej korzystne będzie wybieranie jak najmniejszych $\alpha$ tak aby uniknąć ryzyka odrzucenia prawdziwej hipotezy zerowej. Niestety w praktyce często możemy przeprowadzić tylko ograniczoną ilość badań, eksperymentów, pomiarów, dlatego wybór bardzo małego poziomu istotności nie jest opłacalny. Zwykle przyjmujemy $\alpha=0.05$ (tzn. jesteśmy skłonni popełnić jeden błąd na 20 przypadków). P-wartość nie zależy od poziomu istotności.

\section*{Zadanie 3}
\textbf{Błąd I rodzaju} - prawdopodobieństwo odrzucenia hipotezy zerowej, gdy ta jest prawdziwa. Jego teoretyczna wartość jest równa pozimowi istotności alpha.\\ \\
\textbf{Błąd II rodzaju} - prawdopodobieństwo przyjęcia fałszywej hipotezy zerowej i odrzucenia prawdziwej hipotezy alternatywnej.\\ \\ 
\textbf{Moc testu} - prawdopodobieństwo uniknięcia błędu drugiego rodzaju (1-błąd II rodzaju)
\subsection*{Przypadek dla nieznanej średniej} 
\subsubsection*{Błąd I rodzaju}
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{Z3.Irodzaj.png}
		\caption{Błąd I rodzaju w zależności od poziomu istotności $\alpha$}
	\end{center}
\end{figure}

\begin{table}[H]
	\begin{center}
	\begin{tabular}{|l|l|}
		\hline
		\rowcolor[HTML]{EFEFEF} 
		$\alpha$ & Błąd I rodzaju dla średniej \\ \hline
		0.01 & 0.099                         \\ \hline
		0.05 & 0.049                         \\ \hline
		0.1  & 0.94                         \\ \hline
	\end{tabular}
\caption{Średnia błędu I rodzaju dla 100 symulacji}
	\end{center}
\end{table}

Przeprowadzając 100 symulacji dla prób z rozkładu $N(1.5,~0.2)$ ($H_0: \mu_0 = 1.5$ jest prawdziwa) oraz obliczając średnią z otrzymanych wyników, widzimy że odrzucamy prawdziwą hipotezę zerową w liczbie przypadków bliskiej określonemu teoretycznie poziomowi istotności testu. Oznacza to, że algorytm wykorzystany do testowania hipotez działa poprawnie.

\subsubsection*{Błąd II rodzaju}
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{Z3.mu1.png}
		\caption{$H_1: \mu\ne1.5$}
	\end{center}
\end{figure}
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{Z3.mu2.png}
		\caption{$H_1: \mu>1.5$}
	\end{center}
\end{figure}
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{Z3.mu3.png}
		\caption{$H_1: \mu<1.5$}
	\end{center}
\end{figure}

\begin{table}[H]
\begin{center}
	\begin{tabular}{|l|l|l|l|}
		\hline
		\rowcolor[HTML]{EFEFEF}
		$H_1$                     & $\mu$   & Błąd II rodzaju dla średniej & Moc testu   \\ \hline
		{$\mu\ne1.5$}            			& 1.52 & 0.280                    & 0.720 \\ \cline{2-4} 
		& 1.51 & 0.839                        & 0.161 \\ \cline{2-4} 
		& 1.49 & 0.843                        & 0.157 \\ \cline{2-4} 
		& 1.48 & 0.279                        & 0.721 \\ \hline
		{$\mu>1.5$} 			& 1.51 & 0.527                        & 0.473 \\ \cline{2-4} 
		& 1.52 & 0.064                        & 0.936 \\ \cline{2-4} 
		& 1.53 & 0.001                        & 0.999 \\ \hline
		{$\mu<1.5$}   			 & 1.49 & 0.523                        & 0.477 \\ \cline{2-4} 
		& 1.48 & 0.065                        & 0.935 \\ \cline{2-4} 
		& 1.47 & 0.001                        & 0.999 \\ \hline
	\end{tabular}
\caption{Średnia błędu II rodzaju dla 100 symulacji}
\end{center}
\end{table}
Przeprowadziliśmy 100 symulacji dla prób z rozkładu $N(\mu,0.2)$ dla każdego omawianego $\mu$, które spełnia założenia hipotezy alternatywnej $H_1$. Możemy zauważyć, że im bliżej $\mu_0$ znajduje się $\mu$ tym większe prawdopodobieństwo popełnienia błędu II rodzaju, co skutkuje mniejszą mocą testu. Dla naszych danych gdy $|\mu-\mu_0|\geq 0.02$ test zwraca wyniki, które możemy uznać za rzetelne.
\subsection*{Przypadek dla nieznanej wariancji}
\subsubsection*{Błąd I rodzaju}
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{Z3.Irodzaj.png}
		\caption{Błąd I rodzaju w zależności od poziomu ufności $\alpha$}
	\end{center}
\end{figure}

\begin{table}[H]
	\begin{center}
		\begin{tabular}{|l|l|}
			\hline
			\rowcolor[HTML]{EFEFEF} 
			$\alpha$ & Błąd I rodzaju dla wariancji \\ \hline
			0.01 & 0.01                         \\ \hline
			0.05 & 0.049                         \\ \hline
			0.1  & 0.094                         \\ \hline
		\end{tabular}
		\caption{Średnia błędu I rodzaju dla 100 symulacji}
	\end{center}
\end{table}
Przeprowadzając 100 symulacji dla prób z rozkładu $N(0.2,~1.5)$ (tzn $H_0: \sigma^2_0 = 1.5$ jest prawdziwa) oraz obliczając średnią z otrzymanych wyników, widzimy że odrzucamy prawdziwą hipotezę zerową w liczbie przypadków bliskiej określonemu teoretycznie poziomowi istotności testu. Oznacza to, że algorytm wykorzystany do testowania hipotez działa poprawnie.

\subsubsection*{Błąd II rodzaju}
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{Z3.war1.png}
		\caption{$H_1: \sigma^2\ne1.5$}
	\end{center}
\end{figure}
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{Z3.war2.png}
		\caption{$H_1: \sigma^2>1.5$}
	\end{center}
\end{figure}
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{Z3.war3.png}
		\caption{$H_1: \sigma^2<1.5$}
	\end{center}
\end{figure}

\begin{table}[H]
	\begin{center}
		\begin{tabular}{|l|l|l|l|}
\hline
\rowcolor[HTML]{EFEFEF} 
$H_1$                               & $\sigma$   & Błąd II rodzaju dla watiancji & moc   \\ \hline
& 1.52 & 0.939                        & 0.061 \\ \cline{2-4} 
& 1.51 & 0.947                        & 0.053 \\ \cline{2-4} 
& 1.49 & 0.947                        & 0.053 \\ \cline{2-4} 
{$\sigma\ne1.5$}             & 1.48 & 0.942                        & 0.058 \\ \hline
& 1.51 & 0.932                        & 0.068 \\ \cline{2-4} 
& 1.52 & 0.911                        & 0.089 \\ \cline{2-4} 
{$\sigma>1.5$} & 1.53 & 0.883                        & 0.117 \\ \hline
& 1.49 & 0.934                        & 0.066 \\ \cline{2-4} 
& 1.48 & 0.911                        & 0.089 \\ \cline{2-4} 
{$\sigma<1.5$}    & 1.47 & 0.887                        & 0.113 \\ \hline
		\end{tabular}
		\caption{Mediana błędu II rodzaju dla 100 symulacji}
	\end{center}
\end{table}
Przeprowadziliśmy 100 symulacji dla prób z rozkładu $N(0.2,\sigma^2)$ dla każdego omawianego $\sigma^2$, które spełnia założenia hipotezy alternatywnej $H_1$. Możemy zauważyć, że im bliżej $\sigma_0^2$ znajduje się $\sigma^2$ tym większe prawdopodobieństwo popełnienia błędu II rodzaju, co skutkuje mniejszą mocą testu. Dla naszych $\sigma^2$ moc testu jest bardzo mała - istnieje duża szansa, że odrzucimy prawdziwą hipotezę alternatywną na korzyść fałszywej hipotezy zerowej. \\
\\
\end{document}